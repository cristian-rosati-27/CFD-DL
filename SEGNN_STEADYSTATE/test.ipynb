{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "from torch_geometric.nn import knn_graph\n",
    "from torch_geometric.loader import DataLoader\n",
    "\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import gc\n",
    "\n",
    "from plotly.subplots import make_subplots\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from segnn.segnn import SEGNN\n",
    "from e3nn.o3 import Irreps, spherical_harmonics\n",
    "from segnn.balanced_irreps import BalancedIrreps, WeightBalancedIrreps\n",
    "from segnn.instance_norm import InstanceNorm\n",
    "\n",
    "# use it for input features similar to hemodynamics paper\n",
    "from Utility_functions import print_3D_graph, manual_print_3D_graph, Graph_dataset_with_equiv_features, rotate_graph_coords, translate_graph_coords, denormalize_predictions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import params\n",
    "\n",
    "print('DATADIR', params.DATADIR)\n",
    "print('MODEL_DIR', params.MODEL_DIR)\n",
    "print('NSIM', params.NSIM)\n",
    "print('BATCH_SIZE', params.BATCH_SIZE)\n",
    "\n",
    "print('torch.__version__', torch.__version__)\n",
    "print('torch.cuda.is_available()', torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "# dev = \"cpu\"\n",
    "print(dev)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gc.collect()\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "# change the path accordingly\n",
    "path = os.path.join(params.MODEL_DIR, \"best_model.pt\")\n",
    "print(f\"Loading model checkpoint from {str(path)}\")\n",
    "\n",
    "# checkpoint = torch.load(path)\n",
    "checkpoint = torch.load(path, map_location=torch.device('cpu')) # my laptop only has integraded graphycs\n",
    "\n",
    "input_irreps = checkpoint['input_irreps']\n",
    "hidden_irreps = checkpoint['hidden_irreps']\n",
    "output_irreps = checkpoint['output_irreps']\n",
    "edge_attr_irreps = checkpoint['edge_attr_irreps']\n",
    "node_attr_irreps = checkpoint['node_attr_irreps']\n",
    "task = checkpoint['task']\n",
    "norm=checkpoint['norm']\n",
    "num_layers=checkpoint['num_layers']\n",
    "additional_message_irreps=checkpoint['additional_message_irreps']\n",
    "\n",
    "model = SEGNN(input_irreps=input_irreps,\n",
    "              hidden_irreps=hidden_irreps,\n",
    "              output_irreps=output_irreps,\n",
    "              edge_attr_irreps=edge_attr_irreps,\n",
    "              node_attr_irreps=node_attr_irreps,\n",
    "              task=task,\n",
    "              norm=norm,\n",
    "              num_layers=num_layers,\n",
    "              additional_message_irreps=additional_message_irreps\n",
    "              )\n",
    "\n",
    "model = checkpoint['model']\n",
    "\n",
    "# loss_func = nn.MSELoss()\n",
    "loss_func = nn.L1Loss()\n",
    "\n",
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "print(count_parameters(model))\n",
    "\n",
    "model.to(dev)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gc.collect()\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "# change the path accordingly\n",
    "path = os.path.join(params.DATADIR, \"checkpoints/best_model.pt\")\n",
    "print(f\"Loading model checkpoint from {str(path)}\")\n",
    "\n",
    "# checkpoint = torch.load(path)\n",
    "\n",
    "input_irreps = checkpoint['input_irreps']\n",
    "hidden_irreps = checkpoint['hidden_irreps']\n",
    "output_irreps = checkpoint['output_irreps']\n",
    "edge_attr_irreps = checkpoint['edge_attr_irreps']\n",
    "node_attr_irreps = checkpoint['node_attr_irreps']\n",
    "task = checkpoint['task']\n",
    "norm=checkpoint['norm']\n",
    "num_layers=checkpoint['num_layers']\n",
    "additional_message_irreps=checkpoint['additional_message_irreps']\n",
    "\n",
    "model = SEGNN(input_irreps=input_irreps,\n",
    "              hidden_irreps=hidden_irreps,\n",
    "              output_irreps=output_irreps,\n",
    "              edge_attr_irreps=edge_attr_irreps,\n",
    "              node_attr_irreps=node_attr_irreps,\n",
    "              task=task,\n",
    "              norm=norm,\n",
    "              num_layers=num_layers,\n",
    "              additional_message_irreps=additional_message_irreps\n",
    "              )\n",
    "\n",
    "model = checkpoint['model']\n",
    "\n",
    "# loss_func = nn.MSELoss()\n",
    "loss_func = nn.L1Loss()\n",
    "\n",
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "print(count_parameters(model))\n",
    "\n",
    "model.to(dev)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change the root path accordingly\n",
    "dataset = Graph_dataset_with_equiv_features(params.DATADIR)\n",
    "graph_connectivity = torch.tensor(np.load(params.DATADIR+\"/connectivity.npy\"))\n",
    "print(f\"Loading dataset from {str(params.DATADIR)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset split 80-10-10\n",
    "num_workers = 8\n",
    "\n",
    "dataset_length = len(dataset)\n",
    "if params.NSIM >= 10:\n",
    "    train_length, test_length = train_test_split(range(dataset_length), test_size = 0.2, shuffle = False)\n",
    "    val_length, test_length = train_test_split(range(len(test_length)), test_size = 0.5, shuffle = False)\n",
    "else:\n",
    "    train_length, test_length = list(range(1)), [0]\n",
    "    val_length, test_length = [0], [0]\n",
    "    \n",
    "test_dataset = dataset[test_length]\n",
    "\n",
    "loader = DataLoader(test_dataset, batch_size = 1, shuffle = False, num_workers = num_workers)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "instance_norm = True\n",
    "\n",
    "input_norm = InstanceNorm(input_irreps)\n",
    "edge_norm = InstanceNorm(edge_attr_irreps)\n",
    "# node_norm = InstanceNorm(node_attr_irreps)\n",
    "# output_norm = InstanceNorm(output_irreps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs = []\n",
    "loss = []\n",
    "\n",
    "# mask = True\n",
    "neighbours = params.NEIGHBOURS\n",
    "\n",
    "fluid_nodes = torch.tensor(2)\n",
    "\n",
    "# s is the sample graph\n",
    "for s in tqdm(loader): \n",
    "\n",
    "\n",
    "    # edge_index = knn_graph(s.pos, neighbours, s.batch)\n",
    "    edge_index = graph_connectivity\n",
    "    # print(edge_index)\n",
    "    s.edge_index = edge_index\n",
    "    # print(len(s.pos))\n",
    "    edge_relativePos = (torch.index_select(s.pos, 0, edge_index[1]) - torch.index_select(s.pos, 0, edge_index[0]))\n",
    "    edge_relativeDist = torch.norm(edge_relativePos, dim = -1, keepdim = True) \n",
    "    edge_attr = torch.cat([edge_relativeDist, edge_relativePos], dim = -1) \n",
    "\n",
    "    s.edge_attr = edge_attr\n",
    "    #s.node_attr = s.pos\n",
    "    #print(s.node_attr)\n",
    "            \n",
    "    if instance_norm: # <----------------------------------------------- VERY IMPORTANT!!!\n",
    "        s.x = input_norm(s.x, s.batch)\n",
    "        s.edge_attr = edge_norm(s.edge_attr, s.edge_index[1,:])\n",
    "    \n",
    "    s = s.to(dev)\n",
    "    with torch.no_grad():\n",
    "        \n",
    "        if hasattr(s, \"mask\"):\n",
    "            mask = s.mask\n",
    "        else:\n",
    "            mask = torch.ones(s.x.shape[0], dtype=torch.bool)\n",
    "            \n",
    "        out = model(s)\n",
    "        print(out[0])\n",
    "        #print(out)\n",
    "        loss_val = loss_func(out[mask], s.y[mask])\n",
    "        #print(loss_val)\n",
    "        \n",
    "    \n",
    "    outputs.append(out)\n",
    "    loss.append(loss_val.item())\n",
    "    # print(loss)\n",
    "    # print(len(loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save = True\n",
    "\n",
    "if save:\n",
    "    nploss = np.save('loss.npy', loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,8))\n",
    "plt.plot(range(len(loss)), loss, marker = 'o', markersize=5,\n",
    "         linewidth=0)\n",
    "plt.title('MSE error across test samples', size = 30)\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test set plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loadloss = np.load('loss.npy')\n",
    "\n",
    "plt.figure(figsize=(16,8))\n",
    "\n",
    "plt.plot(range(len(loadloss)), loadloss, marker='o', markersize=5,\n",
    "         linewidth=1, label='MSE on test sample')\n",
    "\n",
    "plt.xlabel('Test samples', size=25)\n",
    "plt.ylabel('Mean Squared Error (MSE)', size=25)\n",
    "plt.title('MSE error across test samples', size=30)\n",
    "plt.grid()\n",
    "legend = plt.legend()\n",
    "legend.get_frame().set_facecolor('lightgray')\n",
    "\n",
    "print(\"Number of test samples:\", len(loadloss))\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Single test plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# idx ofgraph (steady state) to plot\n",
    "test_graph = next(iter(loader))\n",
    "print(test_graph.x)\n",
    "\n",
    "#test_graph = s\n",
    "with torch.no_grad():\n",
    "\n",
    "    # edge_index = knn_graph(test_graph.pos, neighbours, test_graph.batch)\n",
    "    edge_index = graph_connectivity\n",
    "    test_graph.edge_index = edge_index\n",
    "    \n",
    "    edge_relativePos = (torch.index_select(test_graph.pos, 0, edge_index[1]) - torch.index_select(test_graph.pos, 0, edge_index[0]))\n",
    "    edge_relativeDist = torch.norm(edge_relativePos, dim = -1, keepdim = True) \n",
    "    edge_attr = torch.cat([edge_relativeDist, edge_relativePos], dim = -1) \n",
    "    #print(edge_attr)\n",
    "    \n",
    "    test_graph.edge_attr = edge_attr\n",
    "    #test_graph.node_attr = test_graph.pos\n",
    "            \n",
    "    if instance_norm: # <----------------------------------------------- VERY IMPORTANT!!!\n",
    "        test_graph.x = input_norm(test_graph.x, test_graph.batch)\n",
    "        test_graph.edge_attr = edge_norm(test_graph.edge_attr, test_graph.edge_index[1,:])\n",
    "\n",
    "    test_graph = test_graph.to(dev)\n",
    "    # print(test_graph)\n",
    "    # print(test_graph.node_attr)\n",
    "    #print(test_graph.x)\n",
    "\n",
    "    print(f\"test_graph: {test_graph}\")\n",
    "    print(test_graph.x.tolist())\n",
    "    pred = model(test_graph.to(dev)) \n",
    "    # print(pred[0]) # press, vel_x, vel_y, vel_z\n",
    "\n",
    "    # print(test_graph.node_attr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remember that to plot the graphs ignoring the ground truth velocities and pressures, you have\n",
    "# to plot pred[sample.mask], and not simply the \"pred\" tensor (which contains predictions on all nodes,\n",
    "# included the ones that were masked out during training because true values were used in the input, and \n",
    "# that were not taken care of by backpropagation)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ground truth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "### GROUND TRUTH DENORMALIZATION <------------------------------------------------------\n",
    "\n",
    "ground_truth_to_denormalize = {\n",
    "    \"pressure\": test_graph.cpu().y[...,0],\n",
    "    \"vel_x\": test_graph.y[..., 1],\n",
    "    \"vel_y\": test_graph.y[..., 2],\n",
    "    \"vel_z\": test_graph.y[..., 3]\n",
    "}\n",
    "\n",
    "denormalized_ground_truth = denormalize_predictions(ground_truth_to_denormalize, params.DATADIR+'/normalization_params.json')\n",
    "# print(denormalized_ground_truth)\n",
    "true_press = denormalized_ground_truth['pressure']\n",
    "# print(true_press)\n",
    "pred_vel_x = denormalized_ground_truth['vel_x']\n",
    "pred_vel_y = denormalized_ground_truth['vel_y']\n",
    "pred_vel_z = denormalized_ground_truth['vel_z']\n",
    "\n",
    "true_vel = torch.stack([pred_vel_x, pred_vel_y, pred_vel_z], dim=1)\n",
    "true_vel = torch.norm(true_vel[..., 0:3], dim=-1).cpu()\n",
    "# print(true_vel)\n",
    "\n",
    "# print(true_press.shape)\n",
    "# print(true_vel.shape)\n",
    "\n",
    "###\n",
    "\n",
    "\n",
    "# edges = knn_graph(test_graph.pos, neighbours)\n",
    "edges = graph_connectivity\n",
    "# print(len(test_graph.pos))\n",
    "# print(test_graph.pos[1:4].tolist())\n",
    "# print(test_graph.pos[0].tolist())\n",
    "\n",
    "# print(test_graph.num_features)\n",
    "# print(test_graph.pos)\n",
    "\n",
    "# print(test_graph.node_attr[..., 0:4])\n",
    "\n",
    "\n",
    "true_magvel = true_vel # torch.norm(test_graph.cpu().y[...,1:4], dim=-1) # y is ground truth\n",
    "\n",
    "print_3D_graph(test_graph.pos.cpu(), edges = edges, color = true_magvel)\n",
    "print_3D_graph(test_graph.pos.cpu(), edges = edges, color = true_press)\n",
    "# print_3D_graph(test_graph.pos.cpu(), edges = edges, color = test_graph.edge_index) # edge_index is MIS, wrong for testing purposes"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "### DENORMALIZATION <------------------------------------------------------\n",
    "\n",
    "pred_to_denormalize = {\n",
    "\"pressure\": pred[:, 0],\n",
    "\"vel_x\": pred[:, 1],\n",
    "\"vel_y\": pred[:, 2],\n",
    "\"vel_z\": pred[:, 3]\n",
    "}\n",
    "    \n",
    "denormalized_prediction = denormalize_predictions(pred_to_denormalize, params.DATADIR+'/normalization_params.json')\n",
    "# print(denormalized_prediction)\n",
    "pred_pressure = denormalized_prediction['pressure']\n",
    "pred_vel_x = denormalized_prediction['vel_x']\n",
    "pred_vel_y = denormalized_prediction['vel_y']\n",
    "pred_vel_z = denormalized_prediction['vel_z']\n",
    "\n",
    "pred = torch.stack([pred_pressure, pred_vel_x, pred_vel_y, pred_vel_z], dim=1)\n",
    "# print(pred)\n",
    "\n",
    "# print(pred[:, 0].shape)\n",
    "# print(pred[:, 1:4].shape)\n",
    "\n",
    "###\n",
    "\n",
    "\n",
    "\n",
    "# edges = knn_graph(test_graph.pos, neighbours)\n",
    "edges = graph_connectivity\n",
    "\n",
    "for i in range(5):\n",
    "    print(pred[i].tolist())\n",
    "#print(pred[-1].tolist())\n",
    "pred_magvel = torch.norm(pred[...,1:4], dim=-1)\n",
    "pred_press = torch.norm(pred[...,[0]], dim=-1) \n",
    "\n",
    "print_3D_graph(test_graph.pos.cpu(), edges = edges, color = pred_magvel.cpu())\n",
    "print_3D_graph(test_graph.pos.cpu(), edges = edges, color = pred_press.cpu())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "global_min = torch.min(torch.cat((true_magvel.cpu(), pred_magvel.cpu())))\n",
    "print(global_min)\n",
    "global_max = torch.max(torch.cat((true_magvel.cpu(), pred_magvel.cpu())))\n",
    "print(global_max)\n",
    "\n",
    "fig1_colors = true_magvel\n",
    "fig1 = manual_print_3D_graph(test_graph.pos.cpu(), edges.cpu(), fig1_colors.cpu(),\n",
    "                              cmin=global_min.item(), cmax=global_max.item(), colorscale='Viridis') # manual_print_3D_graph needs fig.show() below\n",
    "\n",
    "fig2_colors = pred_magvel\n",
    "fig2 = manual_print_3D_graph(test_graph.pos.cpu(), edges.cpu(), fig2_colors.cpu(),\n",
    "                              cmin=global_min.item(), cmax=global_max.item(), colorscale='Viridis')\n",
    "\n",
    "fig = make_subplots(rows=1, cols=2, specs=[[{'type': 'scatter3d'}, {'type': 'scatter3d'}]],\n",
    "                    subplot_titles=(\"True vel\", \"Pred vel\"))\n",
    "\n",
    "for trace in fig1['data']:\n",
    "    fig.add_trace(trace, row=1, col=1)\n",
    "\n",
    "for trace in fig2['data']:\n",
    "    fig.add_trace(trace, row=1, col=2)\n",
    "\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(true_press.shape)\n",
    "print(pred_press.shape)\n",
    "\n",
    "global_min = torch.min(torch.cat((true_press.cpu(), pred_press.cpu())))\n",
    "print(global_min)\n",
    "global_max = torch.max(torch.cat((true_press.cpu(), pred_press.cpu())))\n",
    "print(global_max)\n",
    "\n",
    "fig3_colors = true_press\n",
    "fig3 = manual_print_3D_graph(test_graph.pos.cpu(), edges.cpu(), fig3_colors, \n",
    "                              cmin=global_min.item(), cmax=global_max.item(), colorscale='Viridis')\n",
    "\n",
    "fig4_colors = pred_press\n",
    "fig4 = manual_print_3D_graph(test_graph.pos.cpu(), edges.cpu(), fig4_colors.cpu(), \n",
    "                              cmin=global_min.item(), cmax=global_max.item(), colorscale='Viridis')\n",
    "\n",
    "fig_press = make_subplots(rows=1, cols=2, specs=[[{'type': 'scatter3d'}, {'type': 'scatter3d'}]],\n",
    "                          subplot_titles=(\"True press\", \"Pred press\"))\n",
    "\n",
    "for trace in fig3['data']:\n",
    "    fig_press.add_trace(trace, row=1, col=1)\n",
    "\n",
    "for trace in fig4['data']:\n",
    "    fig_press.add_trace(trace, row=1, col=2)\n",
    "\n",
    "fig_press.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prediction with INPUT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# idx ofgraph (steady state) to plot\n",
    "test_graph_with_input = next(iter(loader))\n",
    "# print(test_graph_with_input.x)\n",
    "\n",
    "#test_graph_with_input = s\n",
    "with torch.no_grad():\n",
    "\n",
    "    # edge_index = knn_graph(test_graph_with_input.pos, neighbours, test_graph_with_input.batch)\n",
    "    edge_index = graph_connectivity\n",
    "    test_graph_with_input.edge_index = edge_index\n",
    "    \n",
    "    edge_relativePos = (torch.index_select(test_graph_with_input.pos, 0, edge_index[1]) - torch.index_select(test_graph_with_input.pos, 0, edge_index[0]))\n",
    "    edge_relativeDist = torch.norm(edge_relativePos, dim = -1, keepdim = True) \n",
    "    edge_attr = torch.cat([edge_relativeDist, edge_relativePos], dim = -1) \n",
    "    #print(edge_attr)\n",
    "    \n",
    "    test_graph_with_input.edge_attr = edge_attr\n",
    "    #test_graph_with_input.node_attr = test_graph_with_input.pos\n",
    "            \n",
    "    if instance_norm: # <----------------------------------------------- VERY IMPORTANT!!!\n",
    "        test_graph_with_input.x = input_norm(test_graph_with_input.x, test_graph_with_input.batch)\n",
    "        test_graph_with_input.edge_attr = edge_norm(test_graph_with_input.edge_attr, test_graph_with_input.edge_index[1,:])\n",
    "\n",
    "    test_graph_with_input = test_graph_with_input.to(dev)\n",
    "    # print(test_graph_with_input)\n",
    "    # print(test_graph_with_input.node_attr)\n",
    "    #print(test_graph_with_input.x)\n",
    "    \n",
    "    ### INPUT TEST\n",
    "    test_graph_with_input.x[:, 8] = 100 # velocity_range = (320, 360) # m/s\n",
    "    test_graph_with_input.x[:, 9] = -40 # angle_range = (-10, 10) # degrees\n",
    "    print(test_graph_with_input.x)\n",
    "\n",
    "    pred_with_input = model(test_graph_with_input.to(dev)) \n",
    "    # print(pred[0]) # press, vel_x, vel_y, vel_z\n",
    "\n",
    "    # print(test_graph_with_input.node_attr)\n",
    "\n",
    "\n",
    "### DENORMALIZATION <------------------------------------------------------\n",
    "\n",
    "pred_to_denormalize_with_input = {\n",
    "\"pressure\": pred_with_input[:, 0],\n",
    "\"vel_x\": pred_with_input[:, 1],\n",
    "\"vel_y\": pred_with_input[:, 2],\n",
    "\"vel_z\": pred_with_input[:, 3]\n",
    "}\n",
    "    \n",
    "denormalized_prediction_with_input = denormalize_predictions(pred_to_denormalize_with_input, params.DATADIR+'/normalization_params.json')\n",
    "# print(denormalized_prediction)\n",
    "pred_pressure_with_input = denormalized_prediction['pressure']\n",
    "pred_vel_x_with_input = denormalized_prediction['vel_x']\n",
    "pred_vel_y_with_input = denormalized_prediction['vel_y']\n",
    "pred_vel_z_with_input = denormalized_prediction['vel_z']\n",
    "\n",
    "pred_with_input = torch.stack([pred_pressure_with_input, pred_vel_x_with_input, pred_vel_y_with_input, pred_vel_z_with_input], dim=1)\n",
    "print(pred_with_input)\n",
    "\n",
    "# print(pred[:, 0].shape)\n",
    "# print(pred[:, 1:4].shape)\n",
    "\n",
    "###\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# edges = knn_graph(test_graph_with_input.pos, neighbours)\n",
    "edges = graph_connectivity\n",
    "\n",
    "for i in range(5):\n",
    "    print(pred_with_input[i].tolist())\n",
    "#print(pred_with_input[-1].tolist())\n",
    "pred_magvel_with_input = torch.norm(pred_with_input[...,1:4], dim=-1)\n",
    "pred_press_with_input = torch.norm(pred_with_input[...,[0]], dim=-1) \n",
    "\n",
    "# print_3D_graph(test_graph_with_input.pos.cpu(), edges = edges, color = pred_magvel_with_input.cpu())\n",
    "# print_3D_graph(test_graph_with_input.pos.cpu(), edges = edges, color = pred_press_with_input.cpu())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "global_min = torch.min(torch.cat((pred_magvel.cpu(), pred_magvel_with_input.cpu())))\n",
    "print(global_min)\n",
    "global_max = torch.max(torch.cat((pred_magvel.cpu(), pred_magvel_with_input.cpu())))\n",
    "print(global_max)\n",
    "\n",
    "fig5_colors = pred_magvel\n",
    "fig5 = manual_print_3D_graph(test_graph_with_input.pos.cpu(), edges.cpu(), fig5_colors.cpu(), \n",
    "                              cmin=global_min.item(), cmax=global_max.item(), colorscale='Viridis')\n",
    "\n",
    "fig6_colors = pred_magvel_with_input\n",
    "fig6 = manual_print_3D_graph(test_graph_with_input.pos.cpu(), edges.cpu(), fig6_colors.cpu(), \n",
    "                              cmin=global_min.item(), cmax=global_max.item(), colorscale='Viridis')\n",
    "\n",
    "fig_press = make_subplots(rows=1, cols=2, specs=[[{'type': 'scatter3d'}, {'type': 'scatter3d'}]],\n",
    "                          subplot_titles=(\"Vel pred\", \"INPUT Vel pred\"))\n",
    "\n",
    "for trace in fig5['data']:\n",
    "    fig_press.add_trace(trace, row=1, col=1)\n",
    "\n",
    "for trace in fig6['data']:\n",
    "    fig_press.add_trace(trace, row=1, col=2)\n",
    "\n",
    "fig_press.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_vel_with_without_input = 100*abs((pred_magvel.cpu()-pred_magvel_with_input.cpu())/pred_magvel.cpu())\n",
    "# print(loss_vel_with_without_input)\n",
    "\n",
    "plt.figure(figsize=(15,10))\n",
    "\n",
    "loss_vel_flat = loss_vel_with_without_input.cpu()\n",
    "true_mis_flat = [1] * len(loss_vel_flat.cpu())\n",
    "color = plt.cm.hsv(np.linspace(0, 1, len(true_mis_flat)))\n",
    "plt.scatter(range(len(loss_vel_with_without_input)), loss_vel_with_without_input, marker = \".\", c = None, cmap = 'Viridis', s = 10)\n",
    "plt.colorbar()\n",
    "\n",
    "plt.title(\"Input - Non Input VEL difference\", size= 15)\n",
    "plt.xlabel(\"MIS\", size=15)\n",
    "plt.ylabel(\"Loss in %\", size=15)\n",
    "# plt.semilogy()\n",
    "plt.grid()\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_press_with_without_input = 100*abs((pred_press.cpu()-pred_press_with_input.cpu())/pred_press.cpu())\n",
    "# print(loss_press_with_without_input)\n",
    "\n",
    "plt.figure(figsize=(15,10))\n",
    "\n",
    "loss_press_flat = loss_press_with_without_input.cpu()\n",
    "true_mis_flat = [1] * len(loss_press_flat.cpu())\n",
    "color = plt.cm.hsv(np.linspace(0, 1, len(true_mis_flat)))\n",
    "plt.scatter(range(len(loss_press_with_without_input)), loss_press_with_without_input, marker = \".\", c = None, cmap = 'hsv', s = 10)\n",
    "# plt.colorbar()\n",
    "\n",
    "plt.title(\"Input - Non Input PRESS difference\", size= 15)\n",
    "plt.xlabel(\"MIS\", size=15)\n",
    "plt.ylabel(\"Loss in %\", size=15)\n",
    "# plt.semilogy()\n",
    "plt.grid()\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test equivariance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# print(test_graph)\n",
    "# print(pred)\n",
    "# print(true_magvel)\n",
    "print(len(pred))\n",
    "print(len(true_magvel))\n",
    "# print_3D_graph(test_graph.pos, edges = edges, color = true_magvel.cpu())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "translation_vector = np.random.randint(0, 30, size=3)\n",
    "rotation_angle = np.random.randint(40, 80) # rotation is anti clockwise\n",
    "translated_test_graph = translate_graph_coords(test_graph.cpu(), translation_vector)\n",
    "rotated_test_graph = rotate_graph_coords(translated_test_graph.cpu(), rotation_angle, axis=\"x\")\n",
    "# print(rotated_test_graph)\n",
    "\n",
    "rotated_graph_pred = model(rotated_test_graph.to(dev))\n",
    "print(rotated_graph_pred[:10])\n",
    "rotated_graph_magvel_pred = torch.norm(rotated_graph_pred[...,1:4], dim=-1)\n",
    "# print(rotated_graph_pred)\n",
    "# print(rotated_graph_magvel_pred)\n",
    "print(len(rotated_graph_magvel_pred))\n",
    "\n",
    "print_3D_graph(rotated_test_graph.pos, edges = edges, color = true_magvel)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "equivariance_loss = pred - rotated_graph_pred\n",
    "# print(equivariance_loss.tolist())\n",
    "print(f\"Total error is: {equivariance_loss.sum()}\\n\")\n",
    "\n",
    "for row in range(pred.size(0)):\n",
    "    diff = pred[row, :] - rotated_graph_pred[row, :]\n",
    "    if (diff != 0).any():\n",
    "        print(f\"On node {row}: {diff.tolist()}\")\n",
    "\n",
    "print(\" \")\n",
    "print(f\"Graph has: {len(pred)} nodes\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loss analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import re\n",
    "\n",
    "numbers = re.compile(r'(\\d+)')\n",
    "\n",
    "def numericalSort(value):\n",
    "    parts = numbers.split(value)\n",
    "    parts[1::2] = map(int, parts[1::2])\n",
    "    return parts\n",
    "\n",
    "probes_path = os.path.join(params.DATADIR, 'probes')\n",
    "probes = sorted(glob.glob(os.path.join(probes_path, '*.npy')), key = numericalSort)\n",
    "# print(probes[0])\n",
    "\n",
    "probe_data_list = []\n",
    "\n",
    "for data_file in probes:\n",
    "    read_points = np.load(data_file)\n",
    "    probe_data_list.append(torch.from_numpy(read_points))\n",
    "\n",
    "pos_list = probe_data_list\n",
    "#print(pos_list)\n",
    "# print(pos_list[0][...,3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# idx ofgraph (steady state) to plot\n",
    "# test_graph = test_dataset[1]\n",
    "# print(len(test_dataset))\n",
    "\n",
    "loss_vel = []\n",
    "loss_press = []\n",
    "true_mis = []\n",
    "\n",
    "true_vel = []\n",
    "true_press = []\n",
    "\n",
    "i = 1\n",
    "for test_graph in tqdm(loader):\n",
    "        \n",
    "    # print(test_graph.pos[10])\n",
    "\n",
    "    #test_graph = s\n",
    "    with torch.no_grad():\n",
    "\n",
    "        edge_index = graph_connectivity\n",
    "        test_graph.edge_index = edge_index\n",
    "        edge_relativePos = (torch.index_select(test_graph.pos, 0, edge_index[1]) - torch.index_select(test_graph.pos, 0, edge_index[0]))\n",
    "        edge_relativeDist = torch.norm(edge_relativePos, dim = -1, keepdim = True) \n",
    "        edge_attr = torch.cat([edge_relativeDist, edge_relativePos], dim = -1) \n",
    "        test_graph.edge_attr = edge_attr\n",
    "\n",
    "        if instance_norm: # <----------------------------------------------- VERY IMPORTANT!!!\n",
    "            test_graph.x = input_norm(test_graph.x, test_graph.batch)\n",
    "            test_graph.edge_attr = edge_norm(test_graph.edge_attr, test_graph.edge_index[1,:])\n",
    "            \n",
    "\n",
    "        model_pred_before_test = model(test_graph.to(dev)) \n",
    "\n",
    "\n",
    "\n",
    "    ### DENORMALIZATION <------------------------------------------------------\n",
    "\n",
    "    pred_to_denormalize_before_test = {\n",
    "        \"pressure\": model_pred_before_test[:, 0],\n",
    "        \"vel_x\": model_pred_before_test[:, 1],\n",
    "        \"vel_y\": model_pred_before_test[:, 2],\n",
    "        \"vel_z\": model_pred_before_test[:, 3]\n",
    "    }\n",
    "            \n",
    "    denormalized_prediction_before_test = denormalize_predictions(pred_to_denormalize_before_test, params.DATADIR+'/normalization_params.json')\n",
    "    # print(denormalized_prediction)\n",
    "    pred_pressure_before_test = denormalized_prediction_before_test['pressure']\n",
    "    pred_vel_x_before_test = denormalized_prediction_before_test['vel_x']\n",
    "    pred_vel_y_before_test = denormalized_prediction_before_test['vel_y']\n",
    "    pred_vel_z_before_test = denormalized_prediction_before_test['vel_z']\n",
    "\n",
    "    model_pred_before_test = torch.stack([pred_pressure_before_test, pred_vel_x_before_test, pred_vel_y_before_test, pred_vel_z_before_test], dim=1)\n",
    "    # print(pred)\n",
    "\n",
    "    # print(pred[:, 0].shape)\n",
    "    # print(pred[:, 1:4].shape)\n",
    "\n",
    "    ###\n",
    "\n",
    "\n",
    "\n",
    "    # model prediction\n",
    "    out = model_pred_before_test.cpu()\n",
    "    out_vel = torch.norm(out[...,1:4], dim=-1).cpu()\n",
    "    out_press = out[...,0].cpu()\n",
    "    # print(f\"out_vel: {out_vel.tolist()}\")\n",
    "    # print(f\"out_press: {out_press.tolist()}\")\n",
    "    true_vel_i = torch.norm(test_graph.y[...,1:4], dim=-1).cpu()\n",
    "    true_press_i = test_graph.y[...,0].cpu()\n",
    "\n",
    "\n",
    "\n",
    "    ### GROUND TRUTH DENORMALIZATION <------------------------------------------------------\n",
    "\n",
    "    ground_truth_to_denormalize = {\n",
    "        \"pressure\": test_graph.y[..., 0],\n",
    "        \"vel_x\": test_graph.y[..., 1],\n",
    "        \"vel_y\": test_graph.y[..., 2],\n",
    "        \"vel_z\": test_graph.y[..., 3]\n",
    "    }\n",
    "\n",
    "    denormalized_ground_truth = denormalize_predictions(ground_truth_to_denormalize, params.DATADIR+'/normalization_params.json')\n",
    "    # print(denormalized_ground_truth)\n",
    "    true_press_i = denormalized_ground_truth['pressure']\n",
    "    # print(true_press)\n",
    "    pred_vel_x = denormalized_ground_truth['vel_x']\n",
    "    pred_vel_y = denormalized_ground_truth['vel_y']\n",
    "    pred_vel_z = denormalized_ground_truth['vel_z']\n",
    "\n",
    "    true_vel_i = torch.stack([pred_vel_x, pred_vel_y, pred_vel_z], dim=1)\n",
    "    true_vel_i = torch.norm(true_vel_i[..., 0:3], dim=-1).cpu()\n",
    "    # print(true_vel)\n",
    "\n",
    "    # print(true_press.shape)\n",
    "    # print(true_vel.shape)\n",
    "\n",
    "    ###\n",
    "\n",
    "    \n",
    "\n",
    "    true_vel.append(true_vel_i)\n",
    "    true_press.append(true_press_i)\n",
    "    # print(f\"true_vel: {true_vel.tolist()}\")\n",
    "    # print(f\"true_press: {true_press.tolist()}\")\n",
    "\n",
    "    loss_vel.append(100*abs((true_vel_i.cpu()-out_vel.cpu())/true_vel_i.cpu()))\n",
    "    # print(loss_vel)\n",
    "    loss_press.append(100*abs((true_press_i.cpu()-out_press.cpu())/true_press_i.cpu()))\n",
    "\n",
    "    # loss_vel = loss_vel[:(len(loss_vel)-1)]\n",
    "    # loss_press = loss_press[:(len(loss_press)-1)]\n",
    "    # true_mis = true_mis[:(len(true_mis)-1)]\n",
    "\n",
    "    true_mis.append(pos_list[i][...,3])\n",
    "    i += 1\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(len(loss_vel))\n",
    "# print(len(true_mis))\n",
    "\n",
    "# print(loss_vel[0])\n",
    "# print(true_mis[0])\n",
    "\n",
    "plt.figure(figsize=(15,10))\n",
    "\n",
    "true_mis_flat = np.concatenate(true_mis)\n",
    "loss_vel_flat = np.concatenate(loss_vel)\n",
    "color = plt.cm.hsv(np.linspace(0, 1, len(true_mis_flat)))\n",
    "plt.scatter(range(len(loss_vel_flat)), loss_vel_flat, marker = \".\", c = None, cmap = 'hsv', s = 10)\n",
    "# plt.colorbar()\n",
    "\n",
    "plt.title(\"Velocity error on test dataset\", size= 15)\n",
    "plt.xlabel(\"Test Node idx\", size=15)\n",
    "plt.ylabel(\"Loss in %\", size=15)\n",
    "# plt.semilogy()\n",
    "plt.grid()\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "plt.figure(figsize=(15,10))\n",
    "\n",
    "loss_press_flat = np.concatenate(loss_press)\n",
    "# color = np.arange(len(loss_press))\n",
    "color = plt.cm.hsv(np.linspace(0, 1, len(true_mis_flat)))\n",
    "# print(f\"loss_press: {loss_press}\")\n",
    "plt.scatter(range(len(loss_press_flat)), loss_press_flat, marker = \".\", c = None, cmap = 'hsv', s = 10)\n",
    "# plt.colorbar()\n",
    "\n",
    "# for i in range(len(loss_vel_z)):\n",
    "#     plt.text(true_mis[i], loss_vel_z[i], str(i), fontsize=4, ha='right')\n",
    "\n",
    "plt.title(\"Pressure error on test sample\", size= 15)\n",
    "plt.xlabel(\"Test Node idx\", size=15)\n",
    "plt.ylabel(\"Loss in %\", size=15)\n",
    "# plt.semilogy()\n",
    "plt.grid()\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TEST DATASET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# print(true_vel[0])\n",
    "# print(true_mis[0])\n",
    "# print(len(true_vel))\n",
    "# print(len(true_mis))\n",
    "\n",
    "plt.figure(figsize=(15,10))\n",
    "\n",
    "true_vel_flat = np.concatenate(true_vel)\n",
    "color = plt.cm.hsv(np.linspace(0, 1, len(true_mis_flat)))\n",
    "# print(len(color))\n",
    "plt.scatter(range(len(true_vel_flat)), true_vel_flat, marker = \".\", c = None, cmap = 'hsv', s = 10)\n",
    "# plt.colorbar()\n",
    "\n",
    "plt.title(\"True velocity\", size= 15)\n",
    "plt.xlabel(\"Test Node idx\", size=15)\n",
    "plt.ylabel(\"velocity (flow rate)\", size=15)\n",
    "# plt.semilogy()\n",
    "plt.grid()\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# print(true_vel[0])\n",
    "# print(true_mis[0])\n",
    "# print(len(true_vel))\n",
    "# print(len(true_mis))\n",
    "\n",
    "plt.figure(figsize=(15,10))\n",
    "\n",
    "true_press_cpu = [tensor.cpu().numpy() for tensor in true_press]\n",
    "true_press_flat = np.concatenate(true_press_cpu)\n",
    "color = plt.cm.hsv(np.linspace(0, 1, len(true_mis_flat)))\n",
    "# print(len(color))\n",
    "plt.scatter(range(len(true_press_flat)), true_press_flat, marker = \".\", c = None, cmap = 'Viridis', s = 10)\n",
    "# plt.colorbar()\n",
    "\n",
    "plt.title(\"True pressure\", size= 15)\n",
    "plt.xlabel(\"Test Node idx\", size=15)\n",
    "plt.ylabel(\"Pressure\", size=15)\n",
    "# plt.semilogy()\n",
    "plt.grid()\n",
    "\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gpu_test_18",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
